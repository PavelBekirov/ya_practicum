{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "датасет загружен локально\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('toxic_comments.csv')\n",
    "    print('датасет загружен локально')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "    print('датасет загружен с сервера')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "        Unnamed: 0                                               text  toxic\n0                0  Explanation\\nWhy the edits made under my usern...      0\n1                1  D'aww! He matches this background colour I'm s...      0\n2                2  Hey man, I'm really not trying to edit war. It...      0\n3                3  \"\\nMore\\nI can't make any real suggestions on ...      0\n4                4  You, sir, are my hero. Any chance you remember...      0\n...            ...                                                ...    ...\n159287      159446  \":::::And for the second time of asking, when ...      0\n159288      159447  You should be ashamed of yourself \\n\\nThat is ...      0\n159289      159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n159290      159449  And it looks like it was actually you who put ...      0\n159291      159450  \"\\nAnd ... I really don't think you understand...      0\n\n[159292 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>159287</th>\n      <td>159446</td>\n      <td>\":::::And for the second time of asking, when ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159288</th>\n      <td>159447</td>\n      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159289</th>\n      <td>159448</td>\n      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159290</th>\n      <td>159449</td>\n      <td>And it looks like it was actually you who put ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159291</th>\n      <td>159450</td>\n      <td>\"\\nAnd ... I really don't think you understand...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>159292 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/_dbcy3_n789_1_zt9g95px240000gn/T/ipykernel_57774/3784451093.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['len'] = df['text'].str.count('')\n"
     ]
    },
    {
     "data": {
      "text/plain": "        Unnamed: 0       toxic          len\ncount  2000.000000  2000.00000  2000.000000\nmean    999.500000     0.10500   400.337500\nstd     577.494589     0.30663   593.237975\nmin       0.000000     0.00000    20.000000\n25%     499.750000     0.00000    96.000000\n50%     999.500000     0.00000   210.000000\n75%    1499.250000     0.00000   460.250000\nmax    1999.000000     1.00000  4909.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>toxic</th>\n      <th>len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2000.000000</td>\n      <td>2000.00000</td>\n      <td>2000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>999.500000</td>\n      <td>0.10500</td>\n      <td>400.337500</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>577.494589</td>\n      <td>0.30663</td>\n      <td>593.237975</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>499.750000</td>\n      <td>0.00000</td>\n      <td>96.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>999.500000</td>\n      <td>0.00000</td>\n      <td>210.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1499.250000</td>\n      <td>0.00000</td>\n      <td>460.250000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1999.000000</td>\n      <td>1.00000</td>\n      <td>4909.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/_dbcy3_n789_1_zt9g95px240000gn/T/ipykernel_57774/1607224393.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['len'] = df['text'].str.count('')\n"
     ]
    },
    {
     "data": {
      "text/plain": "        Unnamed: 0       toxic          len\ncount  2000.000000  2000.00000  2000.000000\nmean    999.500000     0.10500   400.337500\nstd     577.494589     0.30663   593.237975\nmin       0.000000     0.00000    20.000000\n25%     499.750000     0.00000    96.000000\n50%     999.500000     0.00000   210.000000\n75%    1499.250000     0.00000   460.250000\nmax    1999.000000     1.00000  4909.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>toxic</th>\n      <th>len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2000.000000</td>\n      <td>2000.00000</td>\n      <td>2000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>999.500000</td>\n      <td>0.10500</td>\n      <td>400.337500</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>577.494589</td>\n      <td>0.30663</td>\n      <td>593.237975</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>499.750000</td>\n      <td>0.00000</td>\n      <td>96.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>999.500000</td>\n      <td>0.00000</td>\n      <td>210.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1499.250000</td>\n      <td>0.00000</td>\n      <td>460.250000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1999.000000</td>\n      <td>1.00000</td>\n      <td>4909.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим на распределение по кол-ву слов\n",
    "df['len'] = df['text'].str.count('')\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видим, что 75 квантиль это 460 слов в 1 сообщении, а значит можно ограничить Берту max_length до 512 - много не потеряем."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Возьмем не весь датасет - так как локально мощности не хватит даже с М1 и подключенным GPU\n",
    "df = df[:2000]\n",
    "# df.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмем Бертовскую токсик модель - будем опираться на нее\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('unitary/toxic-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Возьмем Бертовскую токсик модель\n",
    "model = transformers.BertModel.from_pretrained('unitary/toxic-bert')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проставим токены\n",
    "tokenized = df['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Уравниловка\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(2000, 512)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Размер масок\n",
    "attention_mask.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72f255a196034cd4a68710c47ab617f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Собственно эмбединги\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# выборки\n",
    "features = np.concatenate(embeddings)\n",
    "target = df['toxic']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "((2000,), (2000, 768))"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# размеры выборок\n",
    "target.shape, features.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# сплит\n",
    "features_train, features_test, target_train, target_test = train_test_split \\\n",
    "    (features, target, test_size = 0.5, random_state = 12345)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9954751131221719\n",
      "0.9253731343283583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavelbekirov/opt/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Линейная логистическая модель и метрика\n",
    "model_reg = LogisticRegression()\n",
    "model_reg.fit(features_train, target_train)\n",
    "predicts = model_reg.predict(features_train)\n",
    "predicts_test = model_reg.predict(features_test)\n",
    "print(f1_score(predicts, target_train))\n",
    "print(f1_score(predicts_test, target_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "Подобрали модель Бертом и логистической регрессией которая дает результат 0.92 на тесте.\n",
    "Мы использовали маленькую часть выборки для ускорения процесса, но использую хорошие мощности\n",
    "можно перебрать и все объекты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
